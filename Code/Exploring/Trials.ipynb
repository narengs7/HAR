{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "# Serializer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: import_ipynb in /Users/narengs7/Anaconda/anaconda3/lib/python3.7/site-packages (0.1.3)\r\n"
     ]
    }
   ],
   "source": [
    "#[Opional-if already installed] installing import_ipyb for importing another ipyb python code in to this ipyb\n",
    "! pip install import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ReadingData.ipynb\n"
     ]
    }
   ],
   "source": [
    "#Reading already saved train,test data \n",
    "\n",
    "import import_ipynb\n",
    "from ReadingData import *\n",
    "x_train,y_train,x_test,y_test = read_data()\n",
    "num_time_periods, num_sensors,num_classes,input_shape = read_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20868, 240), 240)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Neural Network Librearies\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, GlobalAveragePooling1D,Conv2D, MaxPooling1D, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras import regularizers,optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20868, 240)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20868 samples\n",
      "Epoch 1/40\n",
      "20868/20868 [==============================] - 5s 234us/sample - loss: 3.2469 - accuracy: 0.3641\n",
      "Epoch 2/40\n",
      "20868/20868 [==============================] - 4s 184us/sample - loss: 2.6097 - accuracy: 0.6334\n",
      "Epoch 3/40\n",
      "20868/20868 [==============================] - 4s 184us/sample - loss: 2.2407 - accuracy: 0.7202\n",
      "Epoch 4/40\n",
      "20868/20868 [==============================] - 4s 183us/sample - loss: 1.9942 - accuracy: 0.7553\n",
      "Epoch 5/40\n",
      "20868/20868 [==============================] - 4s 200us/sample - loss: 1.7883 - accuracy: 0.7817\n",
      "Epoch 6/40\n",
      " 6000/20868 [=======>......................] - ETA: 3s - loss: 1.6557 - accuracy: 0.8010"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-34dd5c586b5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-04\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Controlling learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "model = Sequential()\n",
    "model.add(Reshape((80, 3), input_shape=(240,))) #input shape is 240 single array which is changed to 3 array of 80 segment\n",
    "\n",
    "model.add(Conv1D(50, 10, activation='relu', input_shape=(80, 3))) #input segment\n",
    "\n",
    "model.add(Conv1D(40, 10, activation='relu')) \n",
    "model.add(MaxPooling1D())\n",
    "\n",
    "model.add(Conv1D(30, 10, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv1D(10, 10, activation='relu')) \n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(64, activation='relu',kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "opt = optimizers.Adam(lr = 1e-04) #Controlling learning rate \n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=40,batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "print(acc1)\n",
    "y_t1_predict = np.argmax(model.predict(x_train),axis=1)\n",
    "y_train_tmp = np.argmax(y_train,axis=1)\n",
    "y_t2_predict = np.argmax(model.predict(x_test),axis=1)\n",
    "y_test_tmp = np.argmax(y_test,axis=1)\n",
    "acc1 = accuracy_score(y_train_tmp,y_t1_predict),accuracy_score(y_test_tmp,y_t2_predict)\n",
    "if(acc1[1]>acc1[0]):\n",
    "    print(\"Saving Model\")\n",
    "    with open('model_acc_high_1.p','wb') as fp:\n",
    "        pickle.dump(model,fp)\n",
    "acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_138\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_135 (Reshape)        (None, 80, 3)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_522 (Conv1D)          (None, 71, 50)            1550      \n",
      "_________________________________________________________________\n",
      "dropout_448 (Dropout)        (None, 71, 50)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_523 (Conv1D)          (None, 62, 40)            20040     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_137 (MaxPoolin (None, 31, 40)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_524 (Conv1D)          (None, 22, 30)            12030     \n",
      "_________________________________________________________________\n",
      "dropout_449 (Dropout)        (None, 22, 30)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_525 (Conv1D)          (None, 13, 10)            3010      \n",
      "_________________________________________________________________\n",
      "dropout_450 (Dropout)        (None, 13, 10)            0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_129 (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, 64)                704       \n",
      "_________________________________________________________________\n",
      "batch_normalization_122 (Bat (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_451 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_255 (Dense)            (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 37,980\n",
      "Trainable params: 37,852\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((80, 3), input_shape=(240,))) #input shape is 240 single array which is changed to 3 array of 80 segment\n",
    "\n",
    "    model.add(Conv1D(50, 10, activation='relu', input_shape=(80, 3))) #input segment\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Conv1D(40, 10, activation='relu')) \n",
    "    model.add(MaxPooling1D())\n",
    "\n",
    "    model.add(Conv1D(30, 10, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv1D(10, 10, activation='relu')) \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(64, activation='relu',kernel_regularizer=regularizers.l2(0.1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import AveragePooling1D\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Reshape\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  network = Sequential()\n",
    "\n",
    "  network.add(Reshape((80, 3), input_shape=(240,)))\n",
    "\n",
    "  network.add(Conv1D(3, 16, activation='relu', input_shape=(80,3)))\n",
    "  network.add(MaxPooling1D(3))\n",
    "  network.add(BatchNormalization())\n",
    "\n",
    "  network.add(Conv1D(3, 16, activation='relu'))\n",
    "  network.add(MaxPooling1D(3))\n",
    "  network.add(BatchNormalization())\n",
    "\n",
    "  #network.add(GlobalAveragePooling1D())\n",
    "  network.add(Flatten())\n",
    "  network.add(Dropout(0.1))\n",
    "  network.add(layers.Dense(units=64, activation='relu',\n",
    "                           kernel_regularizer=regularizers.l2(0.0)))\n",
    "\n",
    "  network.add(layers.Dense(units=6, activation='softmax'))\n",
    "\n",
    "  # Compile neural network\n",
    "  opt = optimizers.Adam(lr = 1e-04) \n",
    "  network.compile(optimizer = opt,\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "  return network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "20868/20868 [==============================] - 3s 136us/step - loss: 1.3150 - accuracy: 0.5595\n",
      "Epoch 2/40\n",
      "20868/20868 [==============================] - 2s 118us/step - loss: 0.9874 - accuracy: 0.6789\n",
      "Epoch 3/40\n",
      "20868/20868 [==============================] - 3s 124us/step - loss: 0.8653 - accuracy: 0.7051\n",
      "Epoch 4/40\n",
      "20868/20868 [==============================] - 3s 137us/step - loss: 0.7634 - accuracy: 0.7468\n",
      "Epoch 5/40\n",
      "20868/20868 [==============================] - 3s 121us/step - loss: 0.7174 - accuracy: 0.7528\n",
      "Epoch 6/40\n",
      "20868/20868 [==============================] - 2s 118us/step - loss: 0.6867 - accuracy: 0.7595\n",
      "Epoch 7/40\n",
      "20868/20868 [==============================] - 2s 118us/step - loss: 0.6726 - accuracy: 0.7619\n",
      "Epoch 8/40\n",
      "20868/20868 [==============================] - 2s 119us/step - loss: 0.6572 - accuracy: 0.7695\n",
      "Epoch 9/40\n",
      "20868/20868 [==============================] - 3s 120us/step - loss: 0.6491 - accuracy: 0.7720\n",
      "Epoch 10/40\n",
      "20868/20868 [==============================] - 2s 119us/step - loss: 0.6381 - accuracy: 0.7735\n",
      "Epoch 11/40\n",
      "20868/20868 [==============================] - 2s 120us/step - loss: 0.6334 - accuracy: 0.7765\n",
      "Epoch 12/40\n",
      "20868/20868 [==============================] - 3s 122us/step - loss: 0.6221 - accuracy: 0.7801\n",
      "Epoch 13/40\n",
      "20868/20868 [==============================] - 3s 123us/step - loss: 0.6102 - accuracy: 0.7840\n",
      "Epoch 14/40\n",
      "20868/20868 [==============================] - 3s 122us/step - loss: 0.6037 - accuracy: 0.7856\n",
      "Epoch 15/40\n",
      "20868/20868 [==============================] - 3s 123us/step - loss: 0.5940 - accuracy: 0.7882\n",
      "Epoch 16/40\n",
      "20868/20868 [==============================] - 3s 125us/step - loss: 0.5828 - accuracy: 0.7928\n",
      "Epoch 17/40\n",
      "20868/20868 [==============================] - 3s 123us/step - loss: 0.5750 - accuracy: 0.7954\n",
      "Epoch 18/40\n",
      "20868/20868 [==============================] - 3s 122us/step - loss: 0.5627 - accuracy: 0.7995\n",
      "Epoch 19/40\n",
      "20868/20868 [==============================] - 3s 137us/step - loss: 0.5566 - accuracy: 0.8028\n",
      "Epoch 20/40\n",
      "20868/20868 [==============================] - 3s 125us/step - loss: 0.5454 - accuracy: 0.8037\n",
      "Epoch 21/40\n",
      "20868/20868 [==============================] - 3s 125us/step - loss: 0.5401 - accuracy: 0.8058\n",
      "Epoch 22/40\n",
      "20868/20868 [==============================] - 3s 125us/step - loss: 0.5288 - accuracy: 0.8067\n",
      "Epoch 23/40\n",
      "20868/20868 [==============================] - 3s 124us/step - loss: 0.5404 - accuracy: 0.8050\n",
      "Epoch 24/40\n",
      "20868/20868 [==============================] - 3s 126us/step - loss: 0.5192 - accuracy: 0.8108\n",
      "Epoch 25/40\n",
      "20868/20868 [==============================] - 3s 127us/step - loss: 0.5197 - accuracy: 0.8113\n",
      "Epoch 26/40\n",
      "20868/20868 [==============================] - 3s 131us/step - loss: 0.5206 - accuracy: 0.8116\n",
      "Epoch 27/40\n",
      "20868/20868 [==============================] - 3s 133us/step - loss: 0.5122 - accuracy: 0.8134\n",
      "Epoch 28/40\n",
      "20868/20868 [==============================] - 2s 119us/step - loss: 0.5103 - accuracy: 0.8165\n",
      "Epoch 29/40\n",
      "20868/20868 [==============================] - 2s 118us/step - loss: 0.5019 - accuracy: 0.8190\n",
      "Epoch 30/40\n",
      "20868/20868 [==============================] - 3s 122us/step - loss: 0.4966 - accuracy: 0.8182\n",
      "Epoch 31/40\n",
      "20868/20868 [==============================] - 3s 124us/step - loss: 0.5035 - accuracy: 0.8175\n",
      "Epoch 32/40\n",
      "20868/20868 [==============================] - 3s 125us/step - loss: 0.5040 - accuracy: 0.8162\n",
      "Epoch 33/40\n",
      "20868/20868 [==============================] - 3s 124us/step - loss: 0.4969 - accuracy: 0.8185\n",
      "Epoch 34/40\n",
      "20868/20868 [==============================] - 3s 125us/step - loss: 0.4948 - accuracy: 0.8194\n",
      "Epoch 35/40\n",
      "20868/20868 [==============================] - 3s 126us/step - loss: 0.4908 - accuracy: 0.8203\n",
      "Epoch 36/40\n",
      "20868/20868 [==============================] - 3s 130us/step - loss: 0.4902 - accuracy: 0.8212\n",
      "Epoch 37/40\n",
      "20868/20868 [==============================] - 3s 131us/step - loss: 0.4851 - accuracy: 0.8249\n",
      "Epoch 38/40\n",
      "20868/20868 [==============================] - 3s 129us/step - loss: 0.4856 - accuracy: 0.8229\n",
      "Epoch 39/40\n",
      "20868/20868 [==============================] - 2s 120us/step - loss: 0.4780 - accuracy: 0.8258\n",
      "Epoch 40/40\n",
      "20868/20868 [==============================] - 3s 120us/step - loss: 0.4812 - accuracy: 0.8244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa349d41790>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tmp = create_model()\n",
    "model_tmp.fit(x_train,y_train,epochs=40,batch_size=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.816034 using {'batch_size': 30, 'epochs': 40}\n",
      "0.763753 (0.033980) with: {'batch_size': 25, 'epochs': 8}\n",
      "0.795476 (0.018529) with: {'batch_size': 25, 'epochs': 20}\n",
      "0.814405 (0.007158) with: {'batch_size': 25, 'epochs': 30}\n",
      "0.812679 (0.004459) with: {'batch_size': 25, 'epochs': 40}\n",
      "0.738304 (0.033106) with: {'batch_size': 30, 'epochs': 8}\n",
      "0.804294 (0.005182) with: {'batch_size': 30, 'epochs': 20}\n",
      "0.805108 (0.012600) with: {'batch_size': 30, 'epochs': 30}\n",
      "0.816034 (0.014272) with: {'batch_size': 30, 'epochs': 40}\n",
      "0.781533 (0.025916) with: {'batch_size': 20, 'epochs': 8}\n",
      "0.792122 (0.020540) with: {'batch_size': 20, 'epochs': 20}\n",
      "0.806306 (0.003260) with: {'batch_size': 20, 'epochs': 30}\n",
      "0.812343 (0.007856) with: {'batch_size': 20, 'epochs': 40}\n",
      "0.780765 (0.018504) with: {'batch_size': 25, 'epochs': 8}\n",
      "0.807168 (0.008214) with: {'batch_size': 25, 'epochs': 20}\n",
      "0.804053 (0.013164) with: {'batch_size': 25, 'epochs': 30}\n",
      "0.811768 (0.017612) with: {'batch_size': 25, 'epochs': 40}\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model, verbose = 0)\n",
    "# Define the grid search parameters\n",
    "batch_size = [25,30,20,25]\n",
    "epochs = [8,20,30,40]\n",
    "param_grid = dict(batch_size = batch_size, epochs = epochs)\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid)\n",
    "grid_result = grid.fit(x_train,y_train)\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "# model.fit(,epochs=40,batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,  103,    1,    0,  545, 1215],\n",
       "       [   0, 6469,    0,    0,   44,   54],\n",
       "       [   0,    0,  972,   65,   13,    0],\n",
       "       [   0,    0,    4,  811,   18,    0],\n",
       "       [   0,  291,    4,    6, 1138,  903],\n",
       "       [   0,   40,    0,    0,   74, 8098]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train_tmp,y_t_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8380295188805827"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "accuracy_score(y_train_tmp,y_t_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1864\n",
      "           1       0.94      0.99      0.96      6567\n",
      "           2       0.99      0.93      0.96      1050\n",
      "           3       0.92      0.97      0.95       833\n",
      "           4       0.62      0.49      0.55      2342\n",
      "           5       0.79      0.99      0.88      8212\n",
      "\n",
      "    accuracy                           0.84     20868\n",
      "   macro avg       0.71      0.73      0.71     20868\n",
      "weighted avg       0.76      0.84      0.79     20868\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/narengs7/Anaconda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "print(classification_report(y_train_tmp,y_t_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,   14,    0,    1,  119,  516],\n",
       "       [   0, 1903,    0,    0,   27,   60],\n",
       "       [   0,    0,  409,   42,    1,    0],\n",
       "       [   0,    0,    4,  339,   27,    0],\n",
       "       [   0,   40,    0,   15,  289,  381],\n",
       "       [   0,    3,    0,    0,   15, 2379]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "confusion_matrix(y_test_tmp,y_t_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       650\n",
      "           1       0.97      0.96      0.96      1990\n",
      "           2       0.99      0.90      0.95       452\n",
      "           3       0.85      0.92      0.88       370\n",
      "           4       0.60      0.40      0.48       725\n",
      "           5       0.71      0.99      0.83      2397\n",
      "\n",
      "    accuracy                           0.81      6584\n",
      "   macro avg       0.69      0.69      0.68      6584\n",
      "weighted avg       0.74      0.81      0.76      6584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_tmp,y_t_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8078675577156743"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_tmp,y_t_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
